{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:15777'\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:15777'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import pandas as pd\n",
    "from dataset.dataloader import *\n",
    "from dataset.embedding import *\n",
    "from torch_geometric.loader import NeighborLoader, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv', root='./data')\n",
    "split_idx = dataset.get_idx_split()\n",
    "graph = dataset[0]\n",
    "data = {\n",
    "        'train_idx': split_idx['train'], # 90941\n",
    "        'valid_idx': split_idx['valid'], # 29799\n",
    "        'test_idx': split_idx['test'],   # 48603\n",
    "        'graph': graph\n",
    "        }\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10210\n",
      "trunet short videos generation from long videos via story preserving truncation\n",
      "12416\n",
      "aunet attention guided dense upsampling networks for breast mass segmentation in whole mammograms\n",
      "17924\n",
      "tunet incorporating segmentation maps to improve classification\n",
      "21402\n",
      "a scalable low cost uav traffic network unet\n",
      "21644\n",
      "dfunet convolutional neural networks for diabetic foot ulcer classification\n",
      "21718\n",
      "a two stage 3d unet framework for multi class segmentation on full resolution image\n",
      "24558\n",
      "probability map guided bi directional recurrent unet for pancreas segmentation\n",
      "27099\n",
      "colorunet a convolutional classification approach to colorization\n",
      "28432\n",
      "dunet a deformable network for retinal vessel segmentation\n",
      "53447\n",
      "tristounet triplet loss for speaker turn embedding\n",
      "56492\n",
      "multiresunet rethinking the u net architecture for multimodal biomedical image segmentation\n",
      "59068\n",
      "ra unet a hybrid deep attention aware network to extract liver and tumor in ct scans\n",
      "59657\n",
      "traffic map prediction using unet based deep convolutional neural network\n",
      "68728\n",
      "fully dense unet for 2 d sparse photoacoustic tomography artifact removal\n",
      "72067\n",
      "deepunet a deep fully convolutional network for pixel level sea land segmentation\n",
      "76874\n",
      "immunetnas an immune network approach for searching convolutional neural network architectures\n",
      "77360\n",
      "h denseunet hybrid densely connected unet for liver and liver tumor segmentation from ct volumes\n",
      "79173\n",
      "unet a nested u net architecture for medical image segmentation\n",
      "80072\n",
      "glioma segmentation with cascaded unet\n",
      "81503\n",
      "pnunet anomaly detection using positive and negative noise based on self training procedure\n",
      "88045\n",
      "vunet dynamic scene view synthesis for traversability estimation using an rgb camera\n",
      "88371\n",
      "gp unet lesion detection from weak labels with a 3d regression network\n",
      "95936\n",
      "ivd net intervertebral disc localization and segmentation in mri with a multi modal unet\n",
      "95974\n",
      "prunetrain gradual structured pruning from scratch for faster neural network training\n",
      "107168\n",
      "a symphony conducted by brunet\n",
      "124075\n",
      "fortuneteller predicting microarchitectural attacks via unsupervised deep learning\n",
      "126381\n",
      "resunet a a deep learning framework for semantic segmentation of remotely sensed data\n",
      "129034\n",
      "st unet a spatio temporal u network for graph structured time series modeling\n",
      "133076\n",
      "prunetrain fast neural network training by dynamic sparse model reconfiguration\n",
      "134194\n",
      "drunet a dilated residual u net deep learning network to digitally stain optic nerve head tissues in optical coherence tomography images\n",
      "137376\n",
      "raunet residual attention u net for semantic segmentation of cataract surgical instruments\n",
      "143221\n",
      "cunet a compact unsupervised network for image classification\n",
      "152687\n",
      "munet a highly compact deep convolutional neural network architecture for real time embedded traffic sign classification\n",
      "162150\n",
      "neunets an automated synthesis engine for neural network design\n",
      "165636\n",
      "unethical research how to create a malevolent artificial intelligence\n",
      "169195\n",
      "lunet a deep neural network for network intrusion detection\n"
     ]
    }
   ],
   "source": [
    "titleabs = load_titleabs()\n",
    "titleabs\n",
    "title = 'unet'\n",
    "for i, t in enumerate(titleabs['title']):\n",
    "    if title in t:\n",
    "        print(i), print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{tensor(1): 0,\n",
       " tensor(2): 1,\n",
       " tensor(3): 2,\n",
       " tensor(4): 3,\n",
       " tensor(5): 4,\n",
       " tensor(6): 5,\n",
       " tensor(7): 6,\n",
       " tensor(8): 7,\n",
       " tensor(9): 8,\n",
       " tensor(10): 9,\n",
       " tensor(1): 10,\n",
       " tensor(1): 11}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a = torch.tensor([1,2,3,4,5,6,7,8,9,10, 1, 1])\n",
    "d = {}\n",
    "for i, x in enumerate(a):\n",
    "    d[x] = i\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7499 tensor(42537)\n",
      "7500 tensor(124512)\n"
     ]
    }
   ],
   "source": [
    "def naive_search(a, b=None):\n",
    "    for i in range(graph.edge_index.shape[1]):\n",
    "        if b is not None:\n",
    "            if graph.edge_index[0][i] == a and graph.edge_index[1][i] == b:\n",
    "                print(i)\n",
    "                return\n",
    "        else:\n",
    "            if graph.edge_index[0][i] == a:\n",
    "                print(i, graph.edge_index[1][i])\n",
    "        \n",
    "naive_search(13091)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeIndex([[1024, 1025, 1026,  ..., 3291, 3292, 3293],\n",
       "           [   1,    1,    2,  ..., 2459, 2461, 2462]],\n",
       "          sparse_size=(3294, 3294), nnz=2374, sort_order=col)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'random_walk' from 'torch_geometric.utils' (/home/loping151/anaconda3/envs/dm/lib/python3.10/site-packages/torch_geometric/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random_walk\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Dataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_walk_sampler\u001b[39m(data, start_nodes, walk_length):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'random_walk' from 'torch_geometric.utils' (/home/loping151/anaconda3/envs/dm/lib/python3.10/site-packages/torch_geometric/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "class BiasedRandomWalker:\n",
    "\n",
    "    def __init__(self, db, p: float = 1.2, q: float = 2.0):\n",
    "        self.db = db\n",
    "        self.ret_p = p\n",
    "        self.io_q = q\n",
    "\n",
    "        self.connected_nodes = self._get_connected_nodes()\n",
    "\n",
    "    def _get_connected_nodes(self):\n",
    "\n",
    "        txn = self.db.CreateReadTxn()\n",
    "        vit = txn.GetVertexIterator()\n",
    "\n",
    "        connected_nodes = []\n",
    "        while vit.IsValid():\n",
    "            if vit.GetNumOutEdges()[0] > 0:\n",
    "                connected_nodes.append(vit.GetId())\n",
    "            vit.Next()\n",
    "\n",
    "        txn.Commit()\n",
    "        return connected_nodes\n",
    "\n",
    "    def _normalize(self, weights):\n",
    "        tot = sum(weights)\n",
    "        return [p / tot for p in weights]\n",
    "\n",
    "    def get_probs_uniform(self, txn, vit) -> Tuple[List[int], List[float]]:\n",
    "        nexts = vit.ListDstVids()[0]\n",
    "        probs = [1 / len(nexts)] * len(nexts)\n",
    "        return nexts, probs\n",
    "\n",
    "    def get_probs_biased(self, txn, vit, prev: int) -> Tuple[List[int], List[float]]:\n",
    "        curr_nbrs = vit.ListDstVids()[0]\n",
    "\n",
    "        nexts = []\n",
    "        unnormalized_probs = []\n",
    "        for next in curr_nbrs:\n",
    "            nexts.append(next)\n",
    "            if next == prev:\n",
    "                unnormalized_probs.append(1 / self.ret_p)\n",
    "            elif txn.GetVertexIterator(next).HasEdge(prev):\n",
    "                unnormalized_probs.append(1)\n",
    "            else:\n",
    "                unnormalized_probs.append(1 / self.io_q)\n",
    "\n",
    "        probs = self._normalize(unnormalized_probs)\n",
    "        return nexts, probs\n",
    "\n",
    "    def walk(self, start: int, length: int) -> List[int]:\n",
    "\n",
    "        txn = self.db.CreateReadTxn()\n",
    "        vit = txn.GetVertexIterator(start)\n",
    "\n",
    "        trace = [vit.GetId()]\n",
    "        current_len = 1\n",
    "        \n",
    "        prev = None\n",
    "        \n",
    "        while current_len < length:\n",
    "            if prev is None:\n",
    "                nexts, probs = self.get_probs_uniform(txn, vit)\n",
    "            else:\n",
    "                nexts, probs = self.get_probs_biased(txn, vit, prev)\n",
    "\n",
    "            target = random.choices(nexts, probs)[0]\n",
    "            trace.append(target)\n",
    "\n",
    "            vit.Goto(vid=target, nearest=False)\n",
    "            current_len += 1\n",
    "\n",
    "        txn.Commit()\n",
    "        return trace\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
