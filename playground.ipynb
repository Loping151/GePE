{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:15777'\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:15777'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import pandas as pd\n",
    "from dataset.dataloader import *\n",
    "from dataset.embedding import *\n",
    "from torch_geometric.loader import NeighborLoader, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv', root='./data')\n",
    "split_idx = dataset.get_idx_split()\n",
    "graph = dataset[0]\n",
    "data = {\n",
    "        'train_idx': split_idx['train'], # 90941\n",
    "        'valid_idx': split_idx['valid'], # 29799\n",
    "        'test_idx': split_idx['test'],   # 48603\n",
    "        'graph': graph\n",
    "        }\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21718\n",
      "a two stage 3d unet framework for multi class segmentation on full resolution image\n",
      "deep learning for multi task medical image segmentation in multiple modalities\n",
      "hierarchical 3d fully convolutional networks for multi organ segmentation\n",
      "a self aware sampling scheme to efficiently train fully convolutional networks for semantic segmentation\n",
      "multi views fusion cnn for left ventricular volumes estimation on cardiac mr images\n",
      "deeply recursive convolutional network for image super resolution\n",
      "fast r cnn\n",
      "3d u net learning dense volumetric segmentation from sparse annotation\n",
      "automatic 3d cardiovascular mr segmentation with densely connected volumetric convnets\n",
      "u net convolutional networks for biomedical image segmentation\n",
      "organ at risk segmentation in head and neck ct images by using a two stage segmentation framework based on 3d u net\n",
      "cfun combining faster r cnn and u net network for efficient whole heart segmentation\n",
      "a multi task u net for segmentation with lazy labels\n"
     ]
    }
   ],
   "source": [
    "titleabs = load_titleabs()\n",
    "titleabs\n",
    "title = 'a two stage 3d unet framework for multi class segmentation on full resolution image'\n",
    "for i, t in enumerate(titleabs['title']):\n",
    "    if title in t:\n",
    "        print(i), print(t)\n",
    "\n",
    "col, row = graph.edge_index.numpy().tolist()\n",
    "for src, dst in zip(col, row):\n",
    "    if src == 21718:\n",
    "        print(titleabs['title'][dst])\n",
    "    elif dst == 21718:\n",
    "        print(titleabs['title'][src])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{tensor(1): 0,\n",
       " tensor(2): 1,\n",
       " tensor(3): 2,\n",
       " tensor(4): 3,\n",
       " tensor(5): 4,\n",
       " tensor(6): 5,\n",
       " tensor(7): 6,\n",
       " tensor(8): 7,\n",
       " tensor(9): 8,\n",
       " tensor(10): 9,\n",
       " tensor(1): 10,\n",
       " tensor(1): 11}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a = torch.tensor([1,2,3,4,5,6,7,8,9,10, 1, 1])\n",
    "d = {}\n",
    "for i, x in enumerate(a):\n",
    "    d[x] = i\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7499 tensor(42537)\n",
      "7500 tensor(124512)\n"
     ]
    }
   ],
   "source": [
    "def naive_search(a, b=None):\n",
    "    for i in range(graph.edge_index.shape[1]):\n",
    "        if b is not None:\n",
    "            if graph.edge_index[0][i] == a and graph.edge_index[1][i] == b:\n",
    "                print(i)\n",
    "                return\n",
    "        else:\n",
    "            if graph.edge_index[0][i] == a:\n",
    "                print(i, graph.edge_index[1][i])\n",
    "        \n",
    "naive_search(13091)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeIndex([[1024, 1025, 1026,  ..., 3291, 3292, 3293],\n",
       "           [   1,    1,    2,  ..., 2459, 2461, 2462]],\n",
       "          sparse_size=(3294, 3294), nnz=2374, sort_order=col)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'random_walk' from 'torch_geometric.utils' (/home/loping151/anaconda3/envs/dm/lib/python3.10/site-packages/torch_geometric/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random_walk\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Dataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_walk_sampler\u001b[39m(data, start_nodes, walk_length):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'random_walk' from 'torch_geometric.utils' (/home/loping151/anaconda3/envs/dm/lib/python3.10/site-packages/torch_geometric/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "class BiasedRandomWalker:\n",
    "\n",
    "    def __init__(self, db, p: float = 1.2, q: float = 2.0):\n",
    "        self.db = db\n",
    "        self.ret_p = p\n",
    "        self.io_q = q\n",
    "\n",
    "        self.connected_nodes = self._get_connected_nodes()\n",
    "\n",
    "    def _get_connected_nodes(self):\n",
    "\n",
    "        txn = self.db.CreateReadTxn()\n",
    "        vit = txn.GetVertexIterator()\n",
    "\n",
    "        connected_nodes = []\n",
    "        while vit.IsValid():\n",
    "            if vit.GetNumOutEdges()[0] > 0:\n",
    "                connected_nodes.append(vit.GetId())\n",
    "            vit.Next()\n",
    "\n",
    "        txn.Commit()\n",
    "        return connected_nodes\n",
    "\n",
    "    def _normalize(self, weights):\n",
    "        tot = sum(weights)\n",
    "        return [p / tot for p in weights]\n",
    "\n",
    "    def get_probs_uniform(self, txn, vit) -> Tuple[List[int], List[float]]:\n",
    "        nexts = vit.ListDstVids()[0]\n",
    "        probs = [1 / len(nexts)] * len(nexts)\n",
    "        return nexts, probs\n",
    "\n",
    "    def get_probs_biased(self, txn, vit, prev: int) -> Tuple[List[int], List[float]]:\n",
    "        curr_nbrs = vit.ListDstVids()[0]\n",
    "\n",
    "        nexts = []\n",
    "        unnormalized_probs = []\n",
    "        for next in curr_nbrs:\n",
    "            nexts.append(next)\n",
    "            if next == prev:\n",
    "                unnormalized_probs.append(1 / self.ret_p)\n",
    "            elif txn.GetVertexIterator(next).HasEdge(prev):\n",
    "                unnormalized_probs.append(1)\n",
    "            else:\n",
    "                unnormalized_probs.append(1 / self.io_q)\n",
    "\n",
    "        probs = self._normalize(unnormalized_probs)\n",
    "        return nexts, probs\n",
    "\n",
    "    def walk(self, start: int, length: int) -> List[int]:\n",
    "\n",
    "        txn = self.db.CreateReadTxn()\n",
    "        vit = txn.GetVertexIterator(start)\n",
    "\n",
    "        trace = [vit.GetId()]\n",
    "        current_len = 1\n",
    "        \n",
    "        prev = None\n",
    "        \n",
    "        while current_len < length:\n",
    "            if prev is None:\n",
    "                nexts, probs = self.get_probs_uniform(txn, vit)\n",
    "            else:\n",
    "                nexts, probs = self.get_probs_biased(txn, vit, prev)\n",
    "\n",
    "            target = random.choices(nexts, probs)[0]\n",
    "            trace.append(target)\n",
    "\n",
    "            vit.Goto(vid=target, nearest=False)\n",
    "            current_len += 1\n",
    "\n",
    "        txn.Commit()\n",
    "        return trace\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
