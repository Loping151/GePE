{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:15777'\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:15777'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'LV\\xffL\\xe4\\xaa\\xf9W:\\xa5\\xdf\\xf9\\x13\\xdf\\x99z'\n",
      "16\n",
      "b'\\x8b\\xd7\\x95L@\\xc1\\xe5\\x9a\\x90\\x0fq\\xea:&g2`\\x99\\x15\\xb1'\n",
      "20\n",
      "b'\\x89\\xaa\\x1eX\\x00#r-\\xb6vF\\xe8\\x14\\x9e\\xb2F\\xc7H\\xe1\\x80\\xe3J\\x1c\\xf6y\\xab\\x0bA\\xa4\\x16\\xd9\\x04'\n",
      "32\n",
      "b'67\\t\\xc1\\xbe\\xd1\\x00>\\xf6\\x9eXl\\xbc\\x9dr\\x84\\xf1\\x91g>3\\x96\\x01\\xd9\\x00\\x9a>\\x1925\\xfb\\xcf+z\\x14\\x84l(9\\xafA\\x8a\\xb5.\\n\\x89\\xd6|\\xb7\\xb0\\x8f\\x9b\\xc1_h\\x8a\\x85\\xb4\\x91\\xb8\\xff\\t\\x97\\x1f'\n",
      "64\n",
      "[0.29803922 0.3372549  1.         0.29803922 0.89411765 0.66666667\n",
      " 0.97647059 0.34117647 0.22745098 0.64705882 0.8745098  0.97647059\n",
      " 0.0745098  0.8745098  0.6        0.47843137 0.54509804 0.84313725\n",
      " 0.58431373 0.29803922 0.25098039 0.75686275 0.89803922 0.60392157\n",
      " 0.56470588 0.05882353 0.44313725 0.91764706 0.22745098 0.14901961\n",
      " 0.40392157 0.19607843 0.37647059 0.6        0.08235294 0.69411765\n",
      " 0.5372549  0.66666667 0.11764706 0.34509804 0.         0.1372549\n",
      " 0.44705882 0.17647059 0.71372549 0.4627451  0.2745098  0.90980392\n",
      " 0.07843137 0.61960784 0.69803922 0.2745098  0.78039216 0.28235294\n",
      " 0.88235294 0.50196078 0.89019608 0.29019608 0.10980392 0.96470588\n",
      " 0.4745098  0.67058824 0.04313725 0.25490196 0.64313725 0.08627451\n",
      " 0.85098039 0.01568627 0.21176471 0.21568627 0.03529412 0.75686275\n",
      " 0.74509804 0.81960784 0.         0.24313725 0.96470588 0.61960784\n",
      " 0.34509804 0.42352941 0.7372549  0.61568627 0.44705882 0.51764706\n",
      " 0.94509804 0.56862745 0.40392157 0.24313725 0.2        0.58823529\n",
      " 0.00392157 0.85098039 0.         0.60392157 0.24313725 0.09803922\n",
      " 0.19607843 0.20784314 0.98431373 0.81176471 0.16862745 0.47843137\n",
      " 0.07843137 0.51764706 0.42352941 0.15686275 0.22352941 0.68627451\n",
      " 0.25490196 0.54117647 0.70980392 0.18039216 0.03921569 0.5372549\n",
      " 0.83921569 0.48627451 0.71764706 0.69019608 0.56078431 0.60784314\n",
      " 0.75686275 0.37254902 0.40784314 0.54117647 0.52156863 0.70588235\n",
      " 0.56862745 0.72156863 1.         0.03529412 0.59215686 0.12156863]\n",
      "Vector length: 132\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "def encode_node_id(node_id):\n",
    "    node_id_str = str(node_id)\n",
    "    \n",
    "    hash_functions = [\n",
    "        hashlib.md5,\n",
    "        hashlib.sha1,\n",
    "        hashlib.sha256,\n",
    "        hashlib.sha512\n",
    "        ]\n",
    "    \n",
    "    hash_values = []\n",
    "    \n",
    "    for hash_func in hash_functions:\n",
    "        hash_object = hash_func(node_id_str.encode())\n",
    "        hash_bytes = hash_object.digest()\n",
    "        print(hash_bytes)\n",
    "        hash_ints = [b for b in hash_bytes]\n",
    "        print(len(hash_ints))\n",
    "        hash_values.extend(hash_ints)\n",
    "    \n",
    "    vector = np.array(hash_values) / 255.0\n",
    "    \n",
    "    return vector\n",
    "\n",
    "node_id = 121\n",
    "encoded_vector = encode_node_id(node_id)\n",
    "print(encoded_vector)\n",
    "print(f\"Vector length: {len(encoded_vector)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  8,  1, ...,  9,  6, 17])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.02531}\n"
     ]
    }
   ],
   "source": [
    "from ogb.nodeproppred import Evaluator\n",
    "import torch\n",
    "\n",
    "\n",
    "def evaluate(pred, label):\n",
    "    input_dict = {\"y_true\": label, \"y_pred\": pred}\n",
    "    return Evaluator(name='ogbn-arxiv').eval(input_dict)\n",
    "\n",
    "x = torch.randint(0, 40, (100000, 1))\n",
    "y = torch.randint(0, 40, (100000, 1))\n",
    "print(evaluate(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import pandas as pd\n",
    "from dataset.dataloader import *\n",
    "from dataset.embedding import *\n",
    "from torch_geometric.loader import NeighborLoader, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv', root='./data')\n",
    "split_idx = dataset.get_idx_split()\n",
    "graph = dataset[0]\n",
    "data = {\n",
    "        'train_idx': split_idx['train'], # 90941\n",
    "        'valid_idx': split_idx['valid'], # 29799\n",
    "        'test_idx': split_idx['test'],   # 48603\n",
    "        'graph': graph\n",
    "        }\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{tensor(1): 0,\n",
       " tensor(2): 1,\n",
       " tensor(3): 2,\n",
       " tensor(4): 3,\n",
       " tensor(5): 4,\n",
       " tensor(6): 5,\n",
       " tensor(7): 6,\n",
       " tensor(8): 7,\n",
       " tensor(9): 8,\n",
       " tensor(10): 9,\n",
       " tensor(1): 10,\n",
       " tensor(1): 11}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a = torch.tensor([1,2,3,4,5,6,7,8,9,10, 1, 1])\n",
    "d = {}\n",
    "for i, x in enumerate(a):\n",
    "    d[x] = i\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7499 tensor(42537)\n",
      "7500 tensor(124512)\n"
     ]
    }
   ],
   "source": [
    "def naive_search(a, b=None):\n",
    "    for i in range(graph.edge_index.shape[1]):\n",
    "        if b is not None:\n",
    "            if graph.edge_index[0][i] == a and graph.edge_index[1][i] == b:\n",
    "                print(i)\n",
    "                return\n",
    "        else:\n",
    "            if graph.edge_index[0][i] == a:\n",
    "                print(i, graph.edge_index[1][i])\n",
    "        \n",
    "naive_search(13091)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeIndex([[1024, 1025, 1026,  ..., 3291, 3292, 3293],\n",
       "           [   1,    1,    2,  ..., 2459, 2461, 2462]],\n",
       "          sparse_size=(3294, 3294), nnz=2374, sort_order=col)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'random_walk' from 'torch_geometric.utils' (/home/loping151/anaconda3/envs/dm/lib/python3.10/site-packages/torch_geometric/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random_walk\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Dataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_walk_sampler\u001b[39m(data, start_nodes, walk_length):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'random_walk' from 'torch_geometric.utils' (/home/loping151/anaconda3/envs/dm/lib/python3.10/site-packages/torch_geometric/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "class BiasedRandomWalker:\n",
    "\n",
    "    def __init__(self, db, p: float = 1.2, q: float = 2.0):\n",
    "        self.db = db\n",
    "        self.ret_p = p\n",
    "        self.io_q = q\n",
    "\n",
    "        self.connected_nodes = self._get_connected_nodes()\n",
    "\n",
    "    def _get_connected_nodes(self):\n",
    "\n",
    "        txn = self.db.CreateReadTxn()\n",
    "        vit = txn.GetVertexIterator()\n",
    "\n",
    "        connected_nodes = []\n",
    "        while vit.IsValid():\n",
    "            if vit.GetNumOutEdges()[0] > 0:\n",
    "                connected_nodes.append(vit.GetId())\n",
    "            vit.Next()\n",
    "\n",
    "        txn.Commit()\n",
    "        return connected_nodes\n",
    "\n",
    "    def _normalize(self, weights):\n",
    "        tot = sum(weights)\n",
    "        return [p / tot for p in weights]\n",
    "\n",
    "    def get_probs_uniform(self, txn, vit) -> Tuple[List[int], List[float]]:\n",
    "        nexts = vit.ListDstVids()[0]\n",
    "        probs = [1 / len(nexts)] * len(nexts)\n",
    "        return nexts, probs\n",
    "\n",
    "    def get_probs_biased(self, txn, vit, prev: int) -> Tuple[List[int], List[float]]:\n",
    "        curr_nbrs = vit.ListDstVids()[0]\n",
    "\n",
    "        nexts = []\n",
    "        unnormalized_probs = []\n",
    "        for next in curr_nbrs:\n",
    "            nexts.append(next)\n",
    "            if next == prev:\n",
    "                unnormalized_probs.append(1 / self.ret_p)\n",
    "            elif txn.GetVertexIterator(next).HasEdge(prev):\n",
    "                unnormalized_probs.append(1)\n",
    "            else:\n",
    "                unnormalized_probs.append(1 / self.io_q)\n",
    "\n",
    "        probs = self._normalize(unnormalized_probs)\n",
    "        return nexts, probs\n",
    "\n",
    "    def walk(self, start: int, length: int) -> List[int]:\n",
    "\n",
    "        txn = self.db.CreateReadTxn()\n",
    "        vit = txn.GetVertexIterator(start)\n",
    "\n",
    "        trace = [vit.GetId()]\n",
    "        current_len = 1\n",
    "        \n",
    "        prev = None\n",
    "        \n",
    "        while current_len < length:\n",
    "            if prev is None:\n",
    "                nexts, probs = self.get_probs_uniform(txn, vit)\n",
    "            else:\n",
    "                nexts, probs = self.get_probs_biased(txn, vit, prev)\n",
    "\n",
    "            target = random.choices(nexts, probs)[0]\n",
    "            trace.append(target)\n",
    "\n",
    "            vit.Goto(vid=target, nearest=False)\n",
    "            current_len += 1\n",
    "\n",
    "        txn.Commit()\n",
    "        return trace\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
